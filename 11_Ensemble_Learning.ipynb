{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 앙상블 학습 방법\n",
    "## 1. 용어\n",
    "### 기본 학습기 Base Learner\n",
    "- 개별적으로 학습된 모델\n",
    "- 약한 학습기라고도 함\n",
    "### 강한 학습기 Strong Learner\n",
    "-  여러 개의 약한 학습기를 결합하여 만든 모델\n",
    "### 배깅 Bagging\n",
    "- 여러 개의 모델을 병렬로 학습시키고, 그 결과를 결합하는 방법\n",
    "- 각 모델은 데이터의 부트스트랩 샘플을 사용하여 학습\n",
    "- 대표적으로 랜덤 포레스트Random Forest\n",
    "### 부스팅 Boosting\n",
    "- 여러 개의 모델을 순차적으로 학습시킴\n",
    "- 각 모델은 이전 모델의 오차를 줄이는 데 집중\n",
    "- 대표적으로 에이다부스트 Adaboost, 그레이디언트 부스팅 머신GBM\n",
    "### 스태킹 Stacking\n",
    "- 여러 개의 다른 모델의 예측 결과를 모아서 새로운 모델(메타 모델)을 학습시킴\n",
    "메타 모델은 개별 모델의 예측 결과를 입력으로 받아 최종 예측으로 만듬\n",
    "- 다양한 모델 결합 :  Logistic Regression, SVM, Random Forest 등 다양한 모델을 결합하여 더 강력한 예측 가능\n",
    "## 2. 개념\n",
    "- 여러 개의 기본 모델(개별 예측기 또는 기본 학습기)을 결합하여 더 강력한 예측 모델을 만드는 방법\n",
    "- 개별 모델이 가진 약점을 보완하고, 전체적인 성능을 향상시키는 것이 목적\n",
    "## 3. 배깅 : 부트스트랩 샘플링을 통한 분류 앙상블\n",
    "- 배깅은 부트스트랩 샘플링을 사용하여 여러 개의 모델을 학습시키고, 이 모델들의 예측을 평균 내거나 다수결 투포를 통해 최종 예측을 생성\n",
    "### 4.1 배깅 알고리즘의 작동 방식\n",
    "- 부트스트랩 샘플링 : 원본 데이터셋에서 중복을 허용하여 여러 개의 샘플 뽑음\n",
    "- 각 샘프을 이용하여 모델 학습\n",
    "- 모든 모델의 예측을 결합하여 최종 예측 생성\n",
    "## 5. 약한 학습기를 이용한 에이다부스트\n",
    "- 에이다부스트Adaboost는 약한 학습기를 연속적으로 학습시켜 예측 성능을 향상시키는 부스팅 기법\n",
    "### 5.1 부스팅 작동 원리\n",
    "- 첫번째 모델을 학습시킨다\n",
    "- 모델의 오차를 분석하고, 오차가 큰 데이터 포인트에 가중치를 부여한다.\n",
    "- 다음 모델은 가중치가 부여된 데이터를 사용하여 학습한다\n",
    "- 이 과정을 반복하여 최종 예측 만든다\n",
    "## 요약\n",
    "- 여러 모델의 예측 결과를 결합하여 최종 예측을 만듬\n",
    "- 모델 개별의 성능을 보완하고 예측 성능을 향상 시킴\n",
    "- 배깅, 부스팅, 스태킹, 다수결 투표와 같은 다양한 앙상블 기법 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 데이터 로드\n",
    "fish = pd.read_csv(r'https://bit.ly/fish_csv')\n",
    "fish_target = fish['Species'].to_numpy()\n",
    "fish_input = fish[['Weight', 'Length', 'Diagonal', 'Height', 'Width']].to_numpy()\n",
    "\n",
    "# 데이터 분할\n",
    "train_input, test_input, train_target, test_target = train_test_split(fish_input, fish_target, random_state=42)\n",
    "\n",
    "# 데이터 스케일링\n",
    "ss = StandardScaler()\n",
    "ss.fit(train_input)\n",
    "train_scaled = ss.transform(train_input)\n",
    "test_scaled = ss.transform(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diagonal</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bream</td>\n",
       "      <td>242.0</td>\n",
       "      <td>25.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.5200</td>\n",
       "      <td>4.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bream</td>\n",
       "      <td>290.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>31.2</td>\n",
       "      <td>12.4800</td>\n",
       "      <td>4.3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bream</td>\n",
       "      <td>340.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>12.3778</td>\n",
       "      <td>4.6961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bream</td>\n",
       "      <td>363.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>12.7300</td>\n",
       "      <td>4.4555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bream</td>\n",
       "      <td>430.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.4440</td>\n",
       "      <td>5.1340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Species  Weight  Length  Diagonal   Height   Width\n",
       "0   Bream   242.0    25.4      30.0  11.5200  4.0200\n",
       "1   Bream   290.0    26.3      31.2  12.4800  4.3056\n",
       "2   Bream   340.0    26.5      31.1  12.3778  4.6961\n",
       "3   Bream   363.0    29.0      33.5  12.7300  4.4555\n",
       "4   Bream   430.0    29.0      34.0  12.4440  5.1340"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fish.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 모델 정의 - 3가지 사용\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "svm_model = SVC(kernel='linear', probability=True)\n",
    "logistic_model = LogisticRegression(max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앙상블 모델 정의Voting Classifier\n",
    "# VotingClassifier를 사용하여 개별 모델들을 앙상블로 결합\n",
    "# voting = soft는 각 모델의 예측 확률을 평균 내어 최종 예측\n",
    "voting_model = VotingClassifier(\n",
    "    estimators=[('knn', knn_model), ('svm', svm_model), ('logistic', logistic_model)],\n",
    "    voting='soft'  # soft voting 사용\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "# 앙상블 모델 훈련\n",
    "voting_model.fit(train_scaled, train_target)\n",
    "\n",
    "# 예측\n",
    "voting_y_pred = voting_model.predict(test_scaled)\n",
    "\n",
    "# 정확도 평가\n",
    "print(f\"Voting Classifier Accuracy: {accuracy_score(test_target, voting_y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN 개별 모델 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.47\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_model.fit(train_input, train_target)\n",
    "knn_y_pred = knn_model.predict(test_input)\n",
    "print(f\"KNN Accuracy: {accuracy_score(test_target, knn_y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM 개별 모델 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(train_input, train_target)\n",
    "svm_y_pred = svm_model.predict(test_input)\n",
    "print(f\"SVM Accuracy: {accuracy_score(test_target, svm_y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로지스틱 회귀 개별 모델 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\utw09\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression(max_iter=200)\n",
    "logistic_model.fit(train_input, train_target)\n",
    "logistic_y_pred = logistic_model.predict(test_input)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_score(test_target, logistic_y_pred):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 앙상블 학습의 장점\n",
    "1. 안정성\n",
    "- 앙상블 모델은 여러 모델의 예측을 결합하여 예측의 변동성을 줄인다.\n",
    "- 따라서 개별 모델 하나만 사용할 때보다 더 안정적인 성능을 보임\n",
    "2. 일반화 능력\n",
    "- 다양한 모델을 결합함으로써 과적합overfitting을 방지\n",
    "- 새로운 데이터에 대한 일반화 성능을 향상시킬 수 있음\n",
    "3. 상호 보완\n",
    "- 각 모델이 다른 강점과 약점을 가지기 때문에, 이를 결합함으로써 단일 모델의 약점을 보완할 수 있음\n",
    "## 앙상블 학습의 단점\n",
    "1. 복잡성 증가\n",
    "- 여러 모델을 결합하기 때문에 모델의 구조가 복잡해지고, 이해하고 해석하기 어려움\n",
    "- 예를 들어, 단일 모델의 경우 어떤 특징이 중요한지 파악하기 쉬운데, 앙상블 모델은 여러 모델의 결과를 결합하므로 이러한 해석이 어렵\n",
    "2. 계산 비용\n",
    "- 앙상블 모델은 여러 개의 개별 모델을 학습시키고 예측을 수행해야 하므로, 학습 시간과 계산 비용이 증가\n",
    "- 특히, 많은 수의 개별 모델을 사용하는 배깅이나 부스팅 같은 방법은 리소스가 많이 필요\n",
    "3. 과적합 가능성\n",
    "- 잘못 구성된 앙상블 모델은 오히려 과적합overfitting을 초래\n",
    "- 이는 특히 개별 모델들이 서로 매우 유사한 경우 발생\n",
    "- 예를 들어, 배깅Bagging 방법에서 사용되는 개별 결정 트리들이 매우 깊은 경우, 앙상블 모델이 과적합될 가능성이 있음\n",
    "4. 설정과 튜닝의 어려움\n",
    "- 앙상블 모델은 여러 하이퍼파라미터를 조정해야 하므로, 적절한 설정을 찾는 과정이 복잡하고 시간이 걸림\n",
    "- 특히, 부스팅Boosting 같은 방법은 학습률learning rate, 약한 학습기weak learner의 수 등 여러 하이퍼파라미터를 튜닝\n",
    "5. 디버깅 어려움\n",
    "- 개별 모델에서 발생하는 문제를 추적하고 해결하는 것이 상대적으로 간단한 반면, 앙상블 모델에서는 개별 모델들이 상호작용하는 방식 때문에 문제의 원인을 파악하기 어려움\n",
    "- 이는 특히 예측 성능이 기대에 미치지 못할 때 문제를 해결하는 데 어려움\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
